user config:
seed 666
device 0
scaler StandardScaler()
day_slot 288
n_route 10
n_his 96
n_pred 96
n_train 34
n_val 5
n_test 5
mode 1
n_c 10
model STAGNN_stamp
TPG TPGNN
name lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6
log_path log/TPGNN_r05p02kt3outer_263
crash 263
new_name TPGNN_r05p02kt3outer_263
batch_size 128
lr 0.0001
a 0.1
r 0.5
n_mask 1
adam {'use': True, 'weight_decay': 0.0001}
slr {'use': True, 'step_size': 400, 'gamma': 0.3}
resume False
start_epoch 0
epochs 100
n_layer 1
n_attr 64
n_hid 128
reg_A 0.001
circle 288
drop_prob 0.1
CE {'use': True, 'kernel_size': 1, 'bias': False}
LE {'use': False, 'bias': False}
SE {'use': True, 'separate': True, 'no': False}
TE {'use': True, 'no': True}
attn {'head': 1, 'd_k': 32, 'd_v': 32, 'drop_prob': 0.2}
STstamp {'use': True, 'kt': 3, 'temperature': 1.0}
T4N {'use': True, 'step': 2, 'end_epoch': 10000, 'change_head': True, 'change_enc': True}
stamp_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/time_stamp.npy
data_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/V_France_processed_0.csv
adj_matrix_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/W_France_processed_0.csv
dis_mat tensor([[0.0000, 0.3661, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6136, 0.0000,
         0.0000],
        [0.3661, 0.0000, 0.0000, 0.0000, 0.1098, 0.0000, 0.0000, 0.8975, 0.4288,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.3410, 0.8975, 0.0000, 0.0000, 0.0000, 0.4288,
         0.0000],
        [0.0000, 0.0000, 0.3410, 0.0000, 0.1547, 0.0000, 0.0000, 0.0000, 0.0000,
         0.1494],
        [0.0000, 0.1098, 0.8975, 0.1547, 0.0000, 0.0000, 0.0000, 0.0000, 0.6996,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8104, 0.0000, 0.0000,
         0.2289],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8104, 0.0000, 0.0000, 0.0000,
         0.5594],
        [0.6136, 0.8975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2117,
         0.0000],
        [0.0000, 0.4288, 0.4288, 0.0000, 0.6996, 0.0000, 0.0000, 0.2117, 0.0000,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.1494, 0.0000, 0.2289, 0.5594, 0.0000, 0.0000,
         0.0000]], device='cuda:0')
prefix log/lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6/
checkpoint_temp_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6//temp.pth
checkpoint_best_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6//best.pth
tensorboard_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6/
record_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6/record.txt
eps 0.1
parse <bound method DefaultConfig.parse of <config.DefaultConfig object at 0x7faa2b73a5e0>>
output <bound method DefaultConfig.output of <config.DefaultConfig object at 0x7faa2b73a5e0>>
train: True, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 9792
len(data): 9792, day_slot: 288, n_day: 34
train: False, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 1440
len(data): 1440, day_slot: 288, n_day: 5
train: False, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 1440
len(data): 1440, day_slot: 288, n_day: 5
10 10
epoch 0   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 3.959047115766085 , validation loss: 1.217476487159729
epoch 1   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 3.583778583086454 , validation loss: 0.9984164088964462
epoch 2   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 3.249732127556434 , validation loss: 0.977143183350563
epoch 3   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 3.0730800445263204 , validation loss: 1.0157435983419418
epoch 4   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.9440375658181996 , validation loss: 1.0344885289669037
epoch 5   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.8576253469173727 , validation loss: 1.048823431134224
epoch 6   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.803107032409081 , validation loss: 1.0541831701993942
epoch 7   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.760475516319275 , validation loss: 1.0591592192649841
epoch 8   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.719461514399602 , validation loss: 1.0492325723171234
epoch 9   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.680165694310115 , validation loss: 1.0257120430469513
epoch 10   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.648547282585731 , validation loss: 1.0070964097976685
epoch 11   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.6206551240040707 , validation loss: 1.0045776814222336
epoch 12   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.5938396087059608 , validation loss: 0.977689117193222
epoch 13   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.5696858167648315 , validation loss: 0.984751507639885
epoch 14   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.54504433962015 , validation loss: 0.9605637341737747
epoch 15   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.5216156977873583 , validation loss: 0.9501154869794846
epoch 16   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.498587910945599 , validation loss: 0.9491361677646637
epoch 17   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.477522244820228 , validation loss: 0.9368787407875061
epoch 18   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.4563343066435595 , validation loss: 0.9379147440195084
epoch 19   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.4352630651914158 , validation loss: 0.9339544773101807
epoch 20   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.4150302868623 , validation loss: 0.9237963855266571
epoch 21   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.3944857579011183 , validation loss: 0.9249117374420166
epoch 22   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.3751464165174045 , validation loss: 0.9140450209379196
epoch 23   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.355789844806378 , validation loss: 0.9192071408033371
epoch 24   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.3366455756700955 , validation loss: 0.90574911236763
epoch 25   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.3174336965267477 , validation loss: 0.9002162665128708
epoch 26   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.2986592604563785 , validation loss: 0.8763203322887421
epoch 27   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.2807932725319495 , validation loss: 0.887228474020958
epoch 28   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.2626148553994985 , validation loss: 0.8760873377323151
epoch 29   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.243616901911222 , validation loss: 0.8722955286502838
epoch 30   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.226119747528663 , validation loss: 0.8881297558546066
epoch 31   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.2078018280176015 , validation loss: 0.8584501594305038
epoch 32   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.190901279449463 , validation loss: 0.8749896585941315
epoch 33   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.1738578906426063 , validation loss: 0.8589696437120438
epoch 34   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.155562840975248 , validation loss: 0.8728167116641998
epoch 35   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.139908900627723 , validation loss: 0.8614562451839447
epoch 36   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.1228087773689857 , validation loss: 0.8287186622619629
epoch 37   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.10525277027717 , validation loss: 0.8668099343776703
epoch 38   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.0880079086010275 , validation loss: 0.8484308272600174
epoch 39   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.0713298595868626 , validation loss: 0.828752189874649
epoch 40   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.0557362666496863 , validation loss: 0.8202635496854782
epoch 41   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.0410470412327695 , validation loss: 0.7971721887588501
epoch 42   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.024759109203632 , validation loss: 0.8213939964771271
epoch 43   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 2.0084175008993883 , validation loss: 0.7682373076677322
epoch 44   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.9966696409078746 , validation loss: 0.7849808931350708
epoch 45   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.9797059022463286 , validation loss: 0.7777959853410721
epoch 46   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.9663167641713069 , validation loss: 0.7594481706619263
epoch 47   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.950852788411654 , validation loss: 0.7615059465169907
epoch 48   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.937222421169281 , validation loss: 0.7605739235877991
epoch 49   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.9232932466727037 , validation loss: 0.7551896274089813
epoch 50   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.9080530221645648 , validation loss: 0.7381983250379562
epoch 51   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.8957084875840406 , validation loss: 0.7358911484479904
epoch 52   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.883574439929082 , validation loss: 0.738235205411911
epoch 53   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.869536239367265 , validation loss: 0.7417230159044266
epoch 54   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.8559451424158537 , validation loss: 0.7331147193908691
epoch 55   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.8427206919743464 , validation loss: 0.7332449853420258
epoch 56   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.8294526980473444 , validation loss: 0.733620211482048
epoch 57   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.81708641235645 , validation loss: 0.7262093871831894
epoch 58   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.8041701362683222 , validation loss: 0.7209735661745071
epoch 59   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7913216535861676 , validation loss: 0.722711518406868
epoch 60   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7809455073796785 , validation loss: 0.7157361060380936
epoch 61   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7676721490346468 , validation loss: 0.7045753449201584
epoch 62   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7573788716242864 , validation loss: 0.7090870290994644
epoch 63   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.743654911334698 , validation loss: 0.7234072834253311
epoch 64   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7301087517004747 , validation loss: 0.7071263939142227
epoch 65   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7187072680546687 , validation loss: 0.7032537758350372
epoch 66   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.7082003263326793 , validation loss: 0.6977572590112686
epoch 67   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6955969608747041 , validation loss: 0.700133815407753
epoch 68   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6852261332365184 , validation loss: 0.6937043368816376
epoch 69   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.675935685634613 , validation loss: 0.7038177400827408
epoch 70   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6637748342293959 , validation loss: 0.7048843801021576
epoch 71   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6524768471717834 , validation loss: 0.6893518716096878
epoch 72   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.639893916937021 , validation loss: 0.6885870099067688
epoch 73   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6314238355709956 , validation loss: 0.6814478039741516
epoch 74   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.6211076149573693 , validation loss: 0.6900527477264404
epoch 75   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.609699574800638 , validation loss: 0.6887365430593491
epoch 76   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5987888757999127 , validation loss: 0.6868438124656677
epoch 77   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5876395243864794 , validation loss: 0.6832629144191742
epoch 78   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5779798718599172 , validation loss: 0.6849539279937744
epoch 79   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5672379090235784 , validation loss: 0.6770094633102417
epoch 80   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.557474746153905 , validation loss: 0.6842731982469559
epoch 81   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5474053850540748 , validation loss: 0.6794223040342331
epoch 82   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5366733761934133 , validation loss: 0.6814836263656616
epoch 83   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.527993394778325 , validation loss: 0.6757705956697464
epoch 84   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5182220018826997 , validation loss: 0.6847448199987411
epoch 85   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.5077546789095952 , validation loss: 0.6759434789419174
epoch 86   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4985057298953717 , validation loss: 0.6807598173618317
epoch 87   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4894100702725923 , validation loss: 0.6836168467998505
epoch 88   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4818312984246473 , validation loss: 0.6710264086723328
epoch 89   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4698642263045678 , validation loss: 0.6787678450345993
epoch 90   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4609079636060274 , validation loss: 0.6765861809253693
epoch 91   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.451927437232091 , validation loss: 0.6786124408245087
epoch 92   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4426712072812593 , validation loss: 0.6737444549798965
epoch 93   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4332263469696045 , validation loss: 0.6757144927978516
epoch 94   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4247779250144958 , validation loss: 0.6788239032030106
epoch 95   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.414593178492326 , validation loss: 0.6700775027275085
epoch 96   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.4071155282167287 , validation loss: 0.6840138733386993
tensor(68.5405, device='cuda:0')
MAE: [0.3195468822323247, 0.4197964834494843, 0.464559120919133, 0.49334196042833545, 0.5302629622454111, 0.5469945500935092, 0.5522758221953685, 0.5589823812415304, 0.5768416186333778, 0.6073919086937898, 0.6236697527198793, 0.6347329468493225, 0.6472590567305991, 0.6587749631735544, 0.6665935315349206, 0.6665281082327794, 0.6547418663547058, 0.6532982524707145, 0.6668263372421726, 0.6652224020898035, 0.6756846779790352, 0.6855528016956811, 0.6846025386993226, 0.6756596138612512, 0.6649951504996603, 0.6539716868789041, 0.6492884176543232, 0.6453505671254753, 0.6484356724831861, 0.6440674388806154, 0.630441504677508, 0.6221220647678086] , MAPE: [0.11008021661322027, 0.12109528233030134, 0.17378320048729853, 0.1438532994094439, 0.1676066237493684, 0.09954681307710248, 0.07886762794301325, 0.1252829873864884, 0.11627815152925305, 0.1678441382952715, 0.1635144446209867, 0.17629386399744784, 0.11410775869246978, 0.13396075074002717, 0.08837540689409955, 0.0921589622926447, 0.07925439829976519, 0.08149769190200797, 0.1244125217087891, 0.14517494099459505, 0.1404025431534638, 0.15729418759173042, 0.13698501466715843, 0.12498842795909142, 0.06613547124918827, 0.05219059705573132, 0.014323455839875135, -0.05910878779635448, -0.1402827234104601, -0.09395653899939078, -0.08738663107245265, -0.4542207465142388] %, RMSE: [0.5858808333644261, 0.7119958367962961, 0.7572452856760465, 0.7841765550287101, 0.8304306665804968, 0.8420582366114242, 0.8495223059553749, 0.835170012065244, 0.8513392079166222, 0.8941178840602961, 0.9061721006162202, 0.9118300484521207, 0.9228223700906978, 0.9355115076155337, 0.9440489253417661, 0.9456681294843071, 0.9190306397991642, 0.9013714783149293, 0.9109161614208489, 0.9050794996569946, 0.9152326688408505, 0.9226346505416118, 0.9280816602904304, 0.9187667312620761, 0.9036441113746743, 0.8803711972509972, 0.8719583139394467, 0.8611818610061449, 0.865635853706709, 0.8704510807791352, 0.8578897365941138, 0.8572009109672745]
epoch 97   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.3985934395056505 , validation loss: 0.6811166554689407
tensor(68.4097, device='cuda:0')
MAE: [0.32330882541432054, 0.4165171746064707, 0.466578472731635, 0.49963234344324503, 0.5369796629340782, 0.5514479516352498, 0.5484456541014777, 0.5540777460562507, 0.5745753807286472, 0.6047594897838828, 0.6264545812565334, 0.6372516728175286, 0.6489069860054122, 0.6557676287728947, 0.6612714779284812, 0.6531863563348415, 0.6507394096908188, 0.6515363405573844, 0.670215243845794, 0.6682807933028365, 0.6781271906598404, 0.6816686888189852, 0.6763528047743993, 0.6627944613493902, 0.6489789140109241, 0.6398561411658206, 0.6403092809586027, 0.6338401753007982, 0.636018581460278, 0.6313675517450595, 0.6183805569927641, 0.6085928753467719] , MAPE: [0.11415616516582998, 0.14425614115677818, 0.2044551186641671, 0.17775730914702623, 0.17389343983910424, 0.13498586379837132, 0.09527769579263926, 0.13044844962247243, 0.11362399242349394, 0.1627555796779982, 0.1563301286918829, 0.16295906714636282, 0.11916628796027168, 0.14658567532904046, 0.10133256425470182, 0.08314593319181346, 0.07120882422131601, 0.0898079313589656, 0.1383411725529124, 0.1734146101817071, 0.15238879677211895, 0.15706599865779616, 0.15257220579408465, 0.138833622498817, 0.07326115703505473, 0.05823610671804306, 0.02197708225904675, -0.06469390508450554, -0.1389325886052813, -0.09592402753851931, -0.07105120983016174, -0.457326582827512] %, RMSE: [0.5913353471905827, 0.7049154644516595, 0.7615050815945538, 0.7935869767073175, 0.8383823283302486, 0.8474262562757909, 0.839658897691101, 0.8233487649369963, 0.8432191395619576, 0.8870586510084095, 0.9075201278997169, 0.9148084806760811, 0.9257787295366158, 0.9311322221266247, 0.9368373259798021, 0.9246750133028945, 0.9122818933236441, 0.9024886456946757, 0.9203834175008755, 0.9156546349332005, 0.9271165706546126, 0.922527514398014, 0.9188787609042426, 0.9030469153711752, 0.8848787155131026, 0.8669003762107507, 0.8647109628965387, 0.8517318382575855, 0.8544143634081098, 0.8573233377073212, 0.8439523530816518, 0.840760956628522]
epoch 98   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.389480939278236 , validation loss: 0.6777561902999878
tensor(68.2791, device='cuda:0')
MAE: [0.31922281265758057, 0.4129308520401012, 0.4696430155399649, 0.497752478683569, 0.5319387958448418, 0.5470984040596283, 0.539288669063412, 0.5396291543689278, 0.564168967398978, 0.6003366185129457, 0.6203986850989618, 0.6309434567627104, 0.6420539106962454, 0.6486971369429885, 0.649898987634722, 0.6483436930533882, 0.6481039987884692, 0.6525135206636618, 0.6598387082374281, 0.6588374766672855, 0.6686830273385822, 0.6767467349687034, 0.6679147537486608, 0.6576142300319733, 0.6538995704446564, 0.6484135752993146, 0.6462679080789928, 0.6435666172605814, 0.6463131807024408, 0.6383475298597717, 0.6225286533410862, 0.6128397003182968] , MAPE: [0.09589571263245367, 0.10296210100979619, 0.20337637121226132, 0.16484797617498864, 0.17635330007429842, 0.12106309343775681, 0.08771736103454461, 0.11331271436678116, 0.08566205050456775, 0.15789111026553748, 0.16665366387381958, 0.17151569756865373, 0.10419227621232738, 0.14269019599204652, 0.09973595325396362, 0.08297772078362615, 0.05183541582040393, 0.06934233292861669, 0.12862654884938707, 0.15659241515973563, 0.13073457032022037, 0.16202604562038142, 0.12781923841579293, 0.11508455100209457, 0.06417264412866532, 0.030918040482817006, 0.002610140895319757, -0.09008388992449384, -0.20544513411704118, -0.14625570485021225, -0.07440288526630125, -0.4559661607591253] %, RMSE: [0.5842553802447018, 0.7035081045420472, 0.7737101281301101, 0.7950972469283437, 0.8324276712179778, 0.8428689226052327, 0.8283964461305157, 0.8016355070622885, 0.8299940024997118, 0.885714324650562, 0.9058190630287895, 0.9102709917871741, 0.915712401687649, 0.9211061071752348, 0.9186977071742988, 0.9147737302740847, 0.9051008585391208, 0.9008463100261079, 0.9017471394451471, 0.8992433714076712, 0.9054688697301126, 0.9094478510206345, 0.9012195086571233, 0.8884267679009757, 0.882499513952376, 0.8706308145303343, 0.8671679785208437, 0.8586181929201614, 0.8600610571151047, 0.8590377605927053, 0.843249083725846, 0.8399048577101887]
epoch 99   lr1e-4_bs128_nh128_ra1e-3_dp0.1_wd1e-6_ah2_ck5_kt6 , train loss: 1.380137704885923 , validation loss: 0.671973317861557
tensor(68.1489, device='cuda:0')
MAE: [0.3170737543030997, 0.4181193840213254, 0.4698961035933912, 0.5022256870479467, 0.5279718969636549, 0.5474555299853541, 0.5562886217733864, 0.5570988718499957, 0.578455270693743, 0.6180326926066857, 0.644629251237229, 0.6505170517499299, 0.6543647863493137, 0.6554887376524047, 0.665101449758621, 0.6676097516640637, 0.6595686525663303, 0.6678047594792911, 0.6973797047501142, 0.6954182833110549, 0.6952423965820524, 0.6957743836578327, 0.6987362492015374, 0.68794406464285, 0.6735045287527681, 0.6749645271945323, 0.6858697817328664, 0.6817339886676943, 0.6685439763352582, 0.6555822242829066, 0.6474431282831068, 0.6404304887450386] , MAPE: [0.11475963474909016, 0.11396895811013011, 0.16612868054028837, 0.15317881313815024, 0.16208698682773248, 0.07037967508664993, 0.0403235727600011, 0.05997251264665671, 0.03093312294090022, 0.06555866186168001, 0.059497859496461254, 0.07364045280329572, 0.03153368356979252, 0.033355129085387854, -0.009644353769616988, -0.007753133079445949, -0.02054764524640482, -0.0031779564957292845, 0.048477157354786915, 0.07452187276651756, 0.06599062041034166, 0.05985479069204003, 0.04644859262331648, 0.029677536849018915, -0.008965716378050125, -0.02911400804546219, -0.04528154495689471, -0.11819361994491251, -0.15531024996378187, -0.14070628361112184, -0.1307888325624715, -0.47015537883961855] %, RMSE: [0.581379635813074, 0.706273468885158, 0.7619858683542928, 0.7944191818431452, 0.8229190643307603, 0.8346772849833558, 0.8392208252610756, 0.8169334092378232, 0.8378380548433035, 0.8869783763043716, 0.9099555867827205, 0.9097921501965175, 0.9097907603857133, 0.9003087300736415, 0.9105052802368669, 0.9193831505832205, 0.8990506180987862, 0.8940712782070074, 0.9266770733643479, 0.9245033211054203, 0.9210656348414891, 0.9114335303344724, 0.9156382050363625, 0.9055871793840484, 0.8846171776585209, 0.8795647772195906, 0.8897294651537195, 0.8855322185412896, 0.8681612458441045, 0.8593305945383644, 0.852507621196723, 0.8515228429361754]
test loss: NIL 
MAE: [0.3170737543030997, 0.4181193840213254, 0.4698961035933912, 0.5022256870479467, 0.5279718969636549, 0.5474555299853541, 0.5562886217733864, 0.5570988718499957, 0.578455270693743, 0.6180326926066857, 0.644629251237229, 0.6505170517499299, 0.6543647863493137, 0.6554887376524047, 0.665101449758621, 0.6676097516640637, 0.6595686525663303, 0.6678047594792911, 0.6973797047501142, 0.6954182833110549, 0.6952423965820524, 0.6957743836578327, 0.6987362492015374, 0.68794406464285, 0.6735045287527681, 0.6749645271945323, 0.6858697817328664, 0.6817339886676943, 0.6685439763352582, 0.6555822242829066, 0.6474431282831068, 0.6404304887450386] , MAPE: [0.11475963474909016, 0.11396895811013011, 0.16612868054028837, 0.15317881313815024, 0.16208698682773248, 0.07037967508664993, 0.0403235727600011, 0.05997251264665671, 0.03093312294090022, 0.06555866186168001, 0.059497859496461254, 0.07364045280329572, 0.03153368356979252, 0.033355129085387854, -0.009644353769616988, -0.007753133079445949, -0.02054764524640482, -0.0031779564957292845, 0.048477157354786915, 0.07452187276651756, 0.06599062041034166, 0.05985479069204003, 0.04644859262331648, 0.029677536849018915, -0.008965716378050125, -0.02911400804546219, -0.04528154495689471, -0.11819361994491251, -0.15531024996378187, -0.14070628361112184, -0.1307888325624715, -0.47015537883961855] %, RMSE: [0.581379635813074, 0.706273468885158, 0.7619858683542928, 0.7944191818431452, 0.8229190643307603, 0.8346772849833558, 0.8392208252610756, 0.8169334092378232, 0.8378380548433035, 0.8869783763043716, 0.9099555867827205, 0.9097921501965175, 0.9097907603857133, 0.9003087300736415, 0.9105052802368669, 0.9193831505832205, 0.8990506180987862, 0.8940712782070074, 0.9266770733643479, 0.9245033211054203, 0.9210656348414891, 0.9114335303344724, 0.9156382050363625, 0.9055871793840484, 0.8846171776585209, 0.8795647772195906, 0.8897294651537195, 0.8855322185412896, 0.8681612458441045, 0.8593305945383644, 0.852507621196723, 0.8515228429361754]
====================
training elapsedd with 275.33 seconds for 100 iterations, the sec/iter = 2.75

MAE_mean: [0.31707375 0.41811938 0.4698961  0.50222569 0.5279719  0.54745553
 0.55628862 0.55709887 0.57845527 0.61803269 0.64462925 0.65051705
 0.65436479 0.65548874 0.66510145 0.66760975 0.65956865 0.66780476
 0.6973797  0.69541828 0.6952424  0.69577438 0.69873625 0.68794406
 0.67350453 0.67496453 0.68586978 0.68173399 0.66854398 0.65558222
 0.64744313 0.64043049] , MAPE_mean: [ 0.11475963  0.11396896  0.16612868  0.15317881  0.16208699  0.07037968
  0.04032357  0.05997251  0.03093312  0.06555866  0.05949786  0.07364045
  0.03153368  0.03335513 -0.00964435 -0.00775313 -0.02054765 -0.00317796
  0.04847716  0.07452187  0.06599062  0.05985479  0.04644859  0.02967754
 -0.00896572 -0.02911401 -0.04528154 -0.11819362 -0.15531025 -0.14070628
 -0.13078883 -0.47015538] , RMSE_mean: [0.58137964 0.70627347 0.76198587 0.79441918 0.82291906 0.83467728
 0.83922083 0.81693341 0.83783805 0.88697838 0.90995559 0.90979215
 0.90979076 0.90030873 0.91050528 0.91938315 0.89905062 0.89407128
 0.92667707 0.92450332 0.92106563 0.91143353 0.91563821 0.90558718
 0.88461718 0.87956478 0.88972947 0.88553222 0.86816125 0.85933059
 0.85250762 0.85152284]

MAE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan] , MAPE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan] , RMSE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
