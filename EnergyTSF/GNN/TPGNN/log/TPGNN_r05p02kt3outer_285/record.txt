user config:
seed 666
device 0
scaler StandardScaler()
day_slot 288
n_route 10
n_his 96
n_pred 96
n_train 34
n_val 5
n_test 5
mode 1
n_c 10
model STAGNN_stamp
TPG TPGNN
name lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6
log_path log/TPGNN_r05p02kt3outer_285
crash 285
new_name TPGNN_r05p02kt3outer_285
batch_size 128
lr 0.0001
a 0.1
r 0.5
n_mask 1
adam {'use': True, 'weight_decay': 0.0001}
slr {'use': True, 'step_size': 400, 'gamma': 0.3}
resume False
start_epoch 0
epochs 100
n_layer 1
n_attr 64
n_hid 128
reg_A 0.001
circle 288
drop_prob 0.3
CE {'use': True, 'kernel_size': 1, 'bias': False}
LE {'use': False, 'bias': False}
SE {'use': True, 'separate': True, 'no': False}
TE {'use': True, 'no': True}
attn {'head': 1, 'd_k': 32, 'd_v': 32, 'drop_prob': 0.2}
STstamp {'use': True, 'kt': 3, 'temperature': 1.0}
T4N {'use': True, 'step': 2, 'end_epoch': 10000, 'change_head': True, 'change_enc': True}
stamp_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/time_stamp.npy
data_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/V_France_processed_0.csv
adj_matrix_path /mnt/webscistorage/cc7738/ws_joella/EnergyTSF/TPGNN/datasets/W_France_processed_0.csv
dis_mat tensor([[0.0000, 0.3661, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6136, 0.0000,
         0.0000],
        [0.3661, 0.0000, 0.0000, 0.0000, 0.1098, 0.0000, 0.0000, 0.8975, 0.4288,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.3410, 0.8975, 0.0000, 0.0000, 0.0000, 0.4288,
         0.0000],
        [0.0000, 0.0000, 0.3410, 0.0000, 0.1547, 0.0000, 0.0000, 0.0000, 0.0000,
         0.1494],
        [0.0000, 0.1098, 0.8975, 0.1547, 0.0000, 0.0000, 0.0000, 0.0000, 0.6996,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8104, 0.0000, 0.0000,
         0.2289],
        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.8104, 0.0000, 0.0000, 0.0000,
         0.5594],
        [0.6136, 0.8975, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2117,
         0.0000],
        [0.0000, 0.4288, 0.4288, 0.0000, 0.6996, 0.0000, 0.0000, 0.2117, 0.0000,
         0.0000],
        [0.0000, 0.0000, 0.0000, 0.1494, 0.0000, 0.2289, 0.5594, 0.0000, 0.0000,
         0.0000]], device='cuda:0')
prefix log/lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6/
checkpoint_temp_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6//temp.pth
checkpoint_best_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6//best.pth
tensorboard_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6/
record_path log/lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6/record.txt
eps 0.1
parse <bound method DefaultConfig.parse of <config.DefaultConfig object at 0x7efee20955e0>>
output <bound method DefaultConfig.output of <config.DefaultConfig object at 0x7efee20955e0>>
train: True, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 9792
len(data): 9792, day_slot: 288, n_day: 34
train: False, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 1440
len(data): 1440, day_slot: 288, n_day: 5
train: False, day_slot: 288, n_his: 96, n_pred: 96, T4N_step: 2
n_slot (calculated): 1440
len(data): 1440, day_slot: 288, n_day: 5
10 10
epoch 0   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 3.984211719953097 , validation loss: 1.2161166667938232
epoch 1   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 3.617125006822439 , validation loss: 1.0077489912509918
epoch 2   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 3.2911299008589525 , validation loss: 0.9567509889602661
epoch 3   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 3.1227636337280273 , validation loss: 1.0037977248430252
epoch 4   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.997439118532034 , validation loss: 0.9993810951709747
epoch 5   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.9107091335149913 , validation loss: 1.0313632190227509
epoch 6   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.8537784814834595 , validation loss: 1.0468051582574844
epoch 7   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.8087797990212073 , validation loss: 1.044064000248909
epoch 8   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.767074319032522 , validation loss: 1.0494006276130676
epoch 9   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.727244808123662 , validation loss: 1.0108798444271088
epoch 10   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.6952529778847327 , validation loss: 0.9956557154655457
epoch 11   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.6663872462052565 , validation loss: 1.0060238689184189
epoch 12   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.6388695515119114 , validation loss: 0.9734812825918198
epoch 13   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.6133772226480336 , validation loss: 0.9780818372964859
epoch 14   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.5874223984204807 , validation loss: 0.9630466997623444
epoch 15   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.562996295782236 , validation loss: 0.968056246638298
epoch 16   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.5390725961098304 , validation loss: 0.9596425592899323
epoch 17   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.5164888271918664 , validation loss: 0.9415957033634186
epoch 18   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.493884508426373 , validation loss: 0.9421482384204865
epoch 19   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.471754926901597 , validation loss: 0.9506670981645584
epoch 20   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.4504095315933228 , validation loss: 0.9385500103235245
epoch 21   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.4286940006109385 , validation loss: 0.9415187388658524
epoch 22   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.408367789708651 , validation loss: 0.9453598856925964
epoch 23   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.3881702973292422 , validation loss: 0.9347686469554901
epoch 24   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.3681733424846945 , validation loss: 0.9301610887050629
epoch 25   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.3486087138836202 , validation loss: 0.9252883046865463
epoch 26   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.3289376130470862 , validation loss: 0.9198406785726547
epoch 27   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.3101707972013035 , validation loss: 0.9202042669057846
epoch 28   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.29145348072052 , validation loss: 0.9145033657550812
epoch 29   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.27253074829395 , validation loss: 0.9118440002202988
epoch 30   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.2548738167836118 , validation loss: 0.9263858795166016
epoch 31   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.2369090777177076 , validation loss: 0.9305620342493057
epoch 32   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.2194303549253025 , validation loss: 0.9377578347921371
epoch 33   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.2019076072252712 , validation loss: 0.9241239577531815
epoch 34   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.184645542731652 , validation loss: 0.9212961941957474
epoch 35   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.1677020146296573 , validation loss: 0.9308468550443649
epoch 36   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.1514467917955837 , validation loss: 0.9078080803155899
epoch 37   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.1342016550210805 , validation loss: 0.9368565231561661
epoch 38   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.117476252409128 , validation loss: 0.948027566075325
epoch 39   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.100647907990676 , validation loss: 0.9208571314811707
epoch 40   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.084048271179199 , validation loss: 0.9172730445861816
epoch 41   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.0682269701590905 , validation loss: 0.9152383357286453
epoch 42   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.0525224667329054 , validation loss: 0.9370150864124298
epoch 43   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.0366648618991556 , validation loss: 0.8758610785007477
epoch 44   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.0224430102568407 , validation loss: 0.9315819293260574
epoch 45   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 2.0064546649272623 , validation loss: 0.9084495157003403
epoch 46   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9914225248190074 , validation loss: 0.8690140694379807
epoch 47   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9749709780399616 , validation loss: 0.8836212009191513
epoch 48   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9613979046161358 , validation loss: 0.8556220233440399
epoch 49   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9451930293670068 , validation loss: 0.8502383083105087
epoch 50   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9311705369215746 , validation loss: 0.8456559479236603
epoch 51   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9176573249009938 , validation loss: 0.8351258486509323
epoch 52   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.9035791342075055 , validation loss: 0.8389467149972916
epoch 53   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.8896680886928852 , validation loss: 0.8164693117141724
epoch 54   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.876156678566566 , validation loss: 0.818997398018837
epoch 55   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.86093113055596 , validation loss: 0.817626416683197
epoch 56   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.8469934509350703 , validation loss: 0.8058622628450394
epoch 57   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.8338755139937768 , validation loss: 0.797004833817482
epoch 58   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.8205842054807222 , validation loss: 0.7848537713289261
epoch 59   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.8084850999025197 , validation loss: 0.7886940687894821
epoch 60   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7965084039247954 , validation loss: 0.7634962797164917
epoch 61   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7831829740450933 , validation loss: 0.7620568573474884
epoch 62   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.771060544710893 , validation loss: 0.7776238322257996
epoch 63   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7581793528336744 , validation loss: 0.7818833440542221
epoch 64   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7462955713272095 , validation loss: 0.7626868486404419
epoch 65   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7340671053299537 , validation loss: 0.7565300911664963
epoch 66   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7219038834938636 , validation loss: 0.7399047911167145
epoch 67   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.7108210508639996 , validation loss: 0.7404695302248001
epoch 68   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6991677238390996 , validation loss: 0.7416565418243408
epoch 69   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6884713448010957 , validation loss: 0.7420476526021957
epoch 70   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6763121577409597 , validation loss: 0.7433751076459885
epoch 71   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.663969438809615 , validation loss: 0.7219576686620712
epoch 72   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.65370479455361 , validation loss: 0.7222944051027298
epoch 73   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6431360794947698 , validation loss: 0.7188805341720581
epoch 74   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6320883356607878 , validation loss: 0.7228452563285828
epoch 75   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6200881692079396 , validation loss: 0.719522699713707
epoch 76   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.6098426488729625 , validation loss: 0.7179837673902512
epoch 77   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5985917173899138 , validation loss: 0.7141260504722595
epoch 78   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5892672217809236 , validation loss: 0.7089421451091766
epoch 79   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.578419015957759 , validation loss: 0.6998352557420731
epoch 80   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5672655288989727 , validation loss: 0.7125839740037918
epoch 81   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5585064658751855 , validation loss: 0.7126116305589676
epoch 82   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.547574703509991 , validation loss: 0.701557844877243
epoch 83   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5365358820328345 , validation loss: 0.7025926858186722
epoch 84   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5270291291750395 , validation loss: 0.7038998603820801
epoch 85   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.517369921390827 , validation loss: 0.7047919780015945
epoch 86   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.5070354296610906 , validation loss: 0.7022392004728317
epoch 87   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4983883912746723 , validation loss: 0.703090488910675
epoch 88   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4888795522543101 , validation loss: 0.6886507272720337
epoch 89   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.478251956976377 , validation loss: 0.6937298029661179
epoch 90   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4684743285179138 , validation loss: 0.6926388293504715
epoch 91   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4597002588785613 , validation loss: 0.6948443651199341
epoch 92   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.450118532547584 , validation loss: 0.6917814165353775
epoch 93   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4416390794974108 , validation loss: 0.6925243735313416
epoch 94   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4321312170762281 , validation loss: 0.6955019682645798
epoch 95   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4232998490333557 , validation loss: 0.6864286959171295
epoch 96   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.414445968774649 , validation loss: 0.6936832666397095
tensor(68.5363, device='cuda:0')
MAE: [0.3346935774824707, 0.44023308050799537, 0.4816865651922051, 0.5157839247165728, 0.5536908499007449, 0.567620673722866, 0.561715880590923, 0.5658298168534931, 0.5884909573896336, 0.6221421080658731, 0.6463850210599371, 0.6646643160581205, 0.6707906915516276, 0.6699399118010223, 0.6785198678206844, 0.6821446301142887, 0.6782949617272723, 0.6746845738304607, 0.6882911998183303, 0.6882541007421834, 0.6868849127920171, 0.6912738324154514, 0.6918648983254674, 0.6888604248774036, 0.6737791414718268, 0.666060212328262, 0.6704397409975759, 0.6620814660018713, 0.6539849604313867, 0.6507120982757242, 0.6440518754317435, 0.638044218516227] , MAPE: [0.1065091385334521, 0.12494294647980703, 0.20261436696281965, 0.16816122790226146, 0.16497370204678333, 0.13238189827032254, 0.11088249067651464, 0.1513542667789368, 0.11593508096695061, 0.16057353316585427, 0.18288495582798261, 0.20001829172088526, 0.1276437891383185, 0.11201120971015549, 0.08949550396349934, 0.10025437934542573, 0.07048386277732789, 0.08232124036797499, 0.11270162907897627, 0.13151098007104628, 0.1281915734351322, 0.11260638924686421, 0.09809659904621532, 0.07865977363768759, 0.02813623827912115, 0.04130613600135287, -0.01587434061858131, -0.07857754290686889, -0.18859821226684928, -0.10373652357361447, -0.06939132677173943, -0.47521425216302265] %, RMSE: [0.620331648539847, 0.7540734484202005, 0.7907104187354834, 0.8288780226732483, 0.8807459233486328, 0.8887034493932164, 0.8702106974391538, 0.8544997397703926, 0.8775527828618652, 0.9216093733869396, 0.9378973402028237, 0.957195566417383, 0.9624522709297814, 0.9577962032323656, 0.9611134671776443, 0.9719417591505282, 0.9530654815547223, 0.9308602529418323, 0.9361077594556864, 0.9312682693665866, 0.9270644083667583, 0.9282707795704312, 0.9326436862885951, 0.9324303275811061, 0.91103495216037, 0.893587661149492, 0.8937116838783848, 0.8792733249822148, 0.8658765240532618, 0.8688044815062304, 0.8654499136207428, 0.8704505739935884]
epoch 97   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.4047416081795325 , validation loss: 0.6988396197557449
tensor(68.4056, device='cuda:0')
MAE: [0.33291511595383594, 0.4353899695906673, 0.480446110641699, 0.522624295980852, 0.5640874120490817, 0.5779911107527688, 0.560922300046329, 0.56396219809434, 0.5904684273918044, 0.6154598743032625, 0.6430343185353679, 0.6615227314810623, 0.6669998142991177, 0.6594650382170281, 0.6679082997515797, 0.6685373258066469, 0.6725475203063455, 0.6679098488251227, 0.6810443633494745, 0.6851180592233066, 0.6864758732614406, 0.6877369481232978, 0.6789346307488254, 0.6695168015806331, 0.6498746356245169, 0.6460574762774728, 0.6473731643053674, 0.6401404373731809, 0.6348253052996606, 0.6308499134153358, 0.6196561981501423, 0.6109852119055145] , MAPE: [0.11906494756970394, 0.12996261503986162, 0.20439538334512034, 0.20675599106264628, 0.1960429568750966, 0.16259689322173657, 0.1399862194325464, 0.18097109732985409, 0.15812326423169298, 0.19018815262812178, 0.21836849401251907, 0.2421045589983462, 0.17443054450612838, 0.160666216329432, 0.14256686580675226, 0.1328554390214514, 0.09891846930256507, 0.1136110363192752, 0.14282886492818583, 0.17227567104927788, 0.1642915436415273, 0.168014602966501, 0.12513079898937463, 0.10170351908918165, 0.049349630150449526, 0.05195551904356143, -0.00018617188453268663, -0.06596108273912063, -0.1641795465182129, -0.08403891834472102, -0.058663227071327914, -0.47304410765026295] %, RMSE: [0.6189537154454424, 0.7503320284456511, 0.8064560850664192, 0.8501540138623199, 0.8985527086314824, 0.9110953697281593, 0.8799582281644521, 0.8540097124105026, 0.8814395913404448, 0.9201183386427606, 0.9511069424717944, 0.9654538637307016, 0.9640790601970227, 0.9503902563816031, 0.9595058494905695, 0.9549570506314987, 0.9485356396840214, 0.9338729414904614, 0.945424488384894, 0.9462061872720023, 0.9420092537297393, 0.9354777882721568, 0.9304078581917363, 0.9168585228115447, 0.8866663342510311, 0.8780948637995413, 0.8789787391082267, 0.8621186395997577, 0.853263050937894, 0.8554867562298295, 0.8483399744699424, 0.8486600638474542]
epoch 98   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.39611449608436 , validation loss: 0.695513516664505
tensor(68.2751, device='cuda:0')
MAE: [0.3348201872461197, 0.44336067325982853, 0.493660162287409, 0.5260143851679894, 0.5592121836589169, 0.5814137953496779, 0.5653147535898828, 0.5608959296391797, 0.5861121934120418, 0.6283327092345535, 0.6590906057784276, 0.672355508316001, 0.6720525980861761, 0.6708769553907447, 0.6754893459825172, 0.6794466654710548, 0.6819569071032798, 0.6883615527845458, 0.6948320362734195, 0.6933254218026612, 0.6946174074972971, 0.7015506294116224, 0.6915964855756803, 0.6824056464823481, 0.670097151513874, 0.6751145472448588, 0.6732494965433767, 0.6601400222229896, 0.6550609250727696, 0.6503910037852132, 0.6399659580293774, 0.6333506622488044] , MAPE: [0.10879328580957702, 0.12361320244375354, 0.21034411299878614, 0.1748904846436326, 0.1641646879388154, 0.12718364309198188, 0.11187353018276272, 0.14182722128804917, 0.0944729143516084, 0.1525341911133278, 0.19050250543288638, 0.20068614072302002, 0.11956702090293829, 0.11265967048001482, 0.08987292837538186, 0.09779883740180575, 0.043432031705784704, 0.07755316465272155, 0.10294083298059611, 0.1204139150477605, 0.10422259702764423, 0.08851600287573955, 0.0729104162364033, 0.06951605795127143, 0.01989968503784711, 0.024323496681913498, -0.03146695369011458, -0.09083417979553318, -0.18283197098886206, -0.11292640624189666, -0.08774926713535193, -0.4857514679785482] %, RMSE: [0.6218059435500767, 0.7647267932386769, 0.829232104182785, 0.8525333934677738, 0.8852279551753395, 0.911943454075358, 0.8797686391432017, 0.839171205174927, 0.8691625024366575, 0.9343190414199548, 0.9667784203852515, 0.9712095998619188, 0.9586850475595067, 0.9542075162360044, 0.9504468960393011, 0.9542361015930968, 0.9473961582345384, 0.947831998835167, 0.9437869196284191, 0.9352022587265391, 0.9285887184582619, 0.9316256274241671, 0.9219172141311596, 0.9076265814754378, 0.892673277573383, 0.8961720051097056, 0.8912748366131086, 0.8698882692887424, 0.8604511584471101, 0.8611689231549415, 0.8562260695281269, 0.8600835703765405]
epoch 99   lr1e-4_bs128_nh128_ra1e-3_dp0.3_wd1e-6_ah2_ck5_kt6 , train loss: 1.3870749932069044 , validation loss: 0.6860460788011551
tensor(68.1447, device='cuda:0')
MAE: [0.3280078038925631, 0.43115309762547616, 0.48168042476740236, 0.5168413930747312, 0.5480346392441695, 0.5643869189777863, 0.5629892392587109, 0.5572981174332425, 0.5829115683025652, 0.6244554459559011, 0.657630516118226, 0.6648129284961782, 0.6587347106725823, 0.6536189282647114, 0.6680710126789882, 0.6764653096730897, 0.6752211398510358, 0.6839532510759597, 0.7089119890238129, 0.7105575971622212, 0.7010208402022949, 0.698012094325434, 0.6999362749662058, 0.6937330184794348, 0.6678735572706486, 0.6722273139429, 0.6859408034906559, 0.6729133452342574, 0.6560191361337285, 0.6495096763497525, 0.6434264554217765, 0.637766406898646] , MAPE: [0.12535944305568544, 0.11905429807675, 0.17853371897237988, 0.16265432605990954, 0.17043226304549253, 0.09827954948219392, 0.06958615625953361, 0.09495310309404847, 0.04690669268583903, 0.09605375822180033, 0.10205451256694115, 0.12690812646770808, 0.06267084664617006, 0.045570521276864555, 0.014443194818861192, 0.020855230201151553, -0.0034180774909657783, 0.03380316962788035, 0.04967020917182174, 0.0906097670175485, 0.07756455407355499, 0.05131391410026987, 0.044486868115420915, 0.0350616669957211, 0.0023087371672148404, -0.0010921637201441702, -0.046208636378641386, -0.11168836764769254, -0.16927922599610234, -0.108438204206391, -0.10226136049474158, -0.48763914789866025] %, RMSE: [0.6132401946540025, 0.7432374796882835, 0.8031567024702697, 0.8352681187122116, 0.8690422823851165, 0.8797818912448121, 0.8651205577458893, 0.8281323442069013, 0.8587796093728156, 0.9159708726044794, 0.9473231000944922, 0.943283237095108, 0.9252924414263914, 0.9109905991495467, 0.9235986779334517, 0.9390600797691544, 0.9287401529439252, 0.9274790992169122, 0.9506523049181832, 0.9476010023176329, 0.9270764355886828, 0.9109207790199071, 0.917341027935337, 0.9122317979961025, 0.8768979155780121, 0.8783489798772027, 0.8928861267721795, 0.8719895210500312, 0.8467706960141425, 0.8429852268695669, 0.8441691647948846, 0.8485449586119626]
test loss: NIL 
MAE: [0.3280078038925631, 0.43115309762547616, 0.48168042476740236, 0.5168413930747312, 0.5480346392441695, 0.5643869189777863, 0.5629892392587109, 0.5572981174332425, 0.5829115683025652, 0.6244554459559011, 0.657630516118226, 0.6648129284961782, 0.6587347106725823, 0.6536189282647114, 0.6680710126789882, 0.6764653096730897, 0.6752211398510358, 0.6839532510759597, 0.7089119890238129, 0.7105575971622212, 0.7010208402022949, 0.698012094325434, 0.6999362749662058, 0.6937330184794348, 0.6678735572706486, 0.6722273139429, 0.6859408034906559, 0.6729133452342574, 0.6560191361337285, 0.6495096763497525, 0.6434264554217765, 0.637766406898646] , MAPE: [0.12535944305568544, 0.11905429807675, 0.17853371897237988, 0.16265432605990954, 0.17043226304549253, 0.09827954948219392, 0.06958615625953361, 0.09495310309404847, 0.04690669268583903, 0.09605375822180033, 0.10205451256694115, 0.12690812646770808, 0.06267084664617006, 0.045570521276864555, 0.014443194818861192, 0.020855230201151553, -0.0034180774909657783, 0.03380316962788035, 0.04967020917182174, 0.0906097670175485, 0.07756455407355499, 0.05131391410026987, 0.044486868115420915, 0.0350616669957211, 0.0023087371672148404, -0.0010921637201441702, -0.046208636378641386, -0.11168836764769254, -0.16927922599610234, -0.108438204206391, -0.10226136049474158, -0.48763914789866025] %, RMSE: [0.6132401946540025, 0.7432374796882835, 0.8031567024702697, 0.8352681187122116, 0.8690422823851165, 0.8797818912448121, 0.8651205577458893, 0.8281323442069013, 0.8587796093728156, 0.9159708726044794, 0.9473231000944922, 0.943283237095108, 0.9252924414263914, 0.9109905991495467, 0.9235986779334517, 0.9390600797691544, 0.9287401529439252, 0.9274790992169122, 0.9506523049181832, 0.9476010023176329, 0.9270764355886828, 0.9109207790199071, 0.917341027935337, 0.9122317979961025, 0.8768979155780121, 0.8783489798772027, 0.8928861267721795, 0.8719895210500312, 0.8467706960141425, 0.8429852268695669, 0.8441691647948846, 0.8485449586119626]
====================
training elapsedd with 273.83 seconds for 100 iterations, the sec/iter = 2.74

MAE_mean: [0.3280078  0.4311531  0.48168042 0.51684139 0.54803464 0.56438692
 0.56298924 0.55729812 0.58291157 0.62445545 0.65763052 0.66481293
 0.65873471 0.65361893 0.66807101 0.67646531 0.67522114 0.68395325
 0.70891199 0.7105576  0.70102084 0.69801209 0.69993627 0.69373302
 0.66787356 0.67222731 0.6859408  0.67291335 0.65601914 0.64950968
 0.64342646 0.63776641] , MAPE_mean: [ 0.12535944  0.1190543   0.17853372  0.16265433  0.17043226  0.09827955
  0.06958616  0.0949531   0.04690669  0.09605376  0.10205451  0.12690813
  0.06267085  0.04557052  0.01444319  0.02085523 -0.00341808  0.03380317
  0.04967021  0.09060977  0.07756455  0.05131391  0.04448687  0.03506167
  0.00230874 -0.00109216 -0.04620864 -0.11168837 -0.16927923 -0.1084382
 -0.10226136 -0.48763915] , RMSE_mean: [0.61324019 0.74323748 0.8031567  0.83526812 0.86904228 0.87978189
 0.86512056 0.82813234 0.85877961 0.91597087 0.9473231  0.94328324
 0.92529244 0.9109906  0.92359868 0.93906008 0.92874015 0.9274791
 0.9506523  0.947601   0.92707644 0.91092078 0.91734103 0.9122318
 0.87689792 0.87834898 0.89288613 0.87198952 0.8467707  0.84298523
 0.84416916 0.84854496]

MAE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan] , MAPE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan] , RMSE_std: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan
 nan nan nan nan nan nan nan nan nan nan nan nan nan nan]
